{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is composed of 5 subtypes of lung cancer and it is severely imbalanced. I have developped a round robin approach using forward features selection and either logistic regression or random forest as classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import array\n",
    "from sklearn import preprocessing\n",
    "from numpy import cov\n",
    "import scipy.linalg as la\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel(r'C:\\Users\\p-emm\\Desktop\\Stage_M1\\Base_de_donn√©es\\Features of IA subtypes.xlsx')\n",
    "df = df.sample(frac=1)\n",
    "X = df.iloc[:,1:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "\n",
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p-emm\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\p-emm\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "X = X.T\n",
    "#Preprocessing the data by removing the outliers using the interquartile range method\n",
    "for index_element,element in enumerate(X):\n",
    "    Q1=np.percentile(element,25)\n",
    "    Q3=np.percentile(element,75)\n",
    "    med = np.percentile(element,50)\n",
    "    IQR = Q3-Q1\n",
    "    for index_value,value in enumerate(element):\n",
    "        if value < (Q1 - 1.5 * IQR) or value > (Q3 + 1.5 * IQR):\n",
    "            X[index_element,index_value] = med\n",
    "X=X.T\n",
    "#Seperating the data into a training set and a validation set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=5,shuffle=True,stratify=Y)\n",
    "\n",
    "#Scaling the data\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some subtypes are under-represented and the dataset not large enough, we are going to proceed to upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 831)\n",
      "(36, 831)\n",
      "(13, 831)\n",
      "(11, 831)\n",
      "(9, 831)\n"
     ]
    }
   ],
   "source": [
    "### STANDARD UPSAMPLING\n",
    "\n",
    "X_conc = pd.concat([X_train,Y_train],axis=1)\n",
    "\n",
    "little_y = X_conc.iloc[:,-1]\n",
    "\n",
    "lepidic = X_conc.loc[little_y == 1]\n",
    "acinar = X_conc.loc[little_y == 3]\n",
    "papillary = X_conc.loc[little_y == 2]\n",
    "micro_papillary = X_conc.loc[little_y == 4]\n",
    "solid = X_conc.loc[little_y == 5]\n",
    "\n",
    "lepidic = resample(lepidic,replace=True,n_samples=60,random_state=27)\n",
    "\n",
    "acinar = resample(acinar,replace=True,n_samples=58,random_state=27)\n",
    "\n",
    "papillary = resample(papillary,replace=True,n_samples=52,random_state=27)\n",
    "\n",
    "micro_papillary = resample(micro_papillary,replace=True,n_samples=49,random_state=7)\n",
    "\n",
    "solid = resample(solid,replace=True,n_samples=40,random_state=2)\n",
    "\n",
    "upsampled = pd.concat([lepidic,acinar,papillary,micro_papillary,solid])\n",
    "upsampled = upsampled.sample(frac=1)\n",
    "X_train = upsampled.iloc[:,:-1]\n",
    "Y_train = upsampled.iloc[:,-1]\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "Y_train = pd.DataFrame(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reassembling the dataset together\n",
    "X_conc = pd.concat([X_train,Y_train],axis=1)\n",
    "little_y = X_conc.iloc[:,-1]\n",
    "\n",
    "lepidic = X_conc.loc[little_y == 1]\n",
    "papillary = X_conc.loc[little_y == 2]\n",
    "acinar = X_conc.loc[little_y == 3]\n",
    "micro_papillary = X_conc.loc[little_y == 4]\n",
    "solid = X_conc.loc[little_y == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round-Robin consists in building a binary classifier for every possible combination of two subtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:  2.5min finished\n",
      "\n",
      "[2019-09-02 02:26:12] Features: 1/5 -- score: 0.95[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2019-09-02 02:28:40] Features: 2/5 -- score: 0.975[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2019-09-02 02:31:03] Features: 3/5 -- score: 0.9833333333333334[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 827 out of 827 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "\n",
      "[2019-09-02 02:33:25] Features: 4/5 -- score: 0.9833333333333334[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 826 out of 826 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s finished\n",
      "\n",
      "[2019-09-02 02:35:49] Features: 5/5 -- score: 0.9833333333333334"
     ]
    }
   ],
   "source": [
    "#Lepidic and Acinar subtypes (LA)\n",
    "LA = pd.concat([lepidic,acinar])\n",
    "LA = LA.sample(frac=1)\n",
    "X_LA_train = LA.iloc[:,:-1]\n",
    "X_LA_train = X_LA_train.values\n",
    "Y_LA_train = LA.iloc[:,-1]\n",
    "Y_LA_train = Y_LA_train.values\n",
    "\n",
    "#Using Forward Feature Selection with KNN approach\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform',n_jobs=-1)\n",
    "sfs1 = sfs(knn, \n",
    "           k_features=5, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs1 = sfs1.fit(X_LA_train, Y_LA_train)\n",
    "feat_cols_1 = list(sfs1.k_feature_idx_) #list containing the selected features\n",
    "\n",
    "#Implementing the Binary Classifier for Lepidic and Acinar subtypes\n",
    "rfc1 = RandomForestClassifier(n_estimators=30, random_state=42, max_features=2)\n",
    "# rfc1 = LogisticRegression(C=50, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc1.fit(X_LA_train[:, feat_cols_1], Y_LA_train)\n",
    "\n",
    "print(rfc1.score(X_LA_train[:, feat_cols_1],Y_LA_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the exact same approach for the next couples of subtypes (Lepidic and Micro-Papillary, etc .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:  2.3min finished\n",
      "\n",
      "[2019-09-02 02:38:05] Features: 1/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2019-09-02 02:40:26] Features: 2/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908256880733946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "\n",
      "[2019-09-02 02:42:49] Features: 3/3 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "LM = pd.concat([lepidic,micro_papillary])\n",
    "LM = LM.sample(frac=1)\n",
    "X_LM_train = LM.iloc[:,:-1]\n",
    "X_LM_train = X_LM_train.values\n",
    "Y_LM_train = LM.iloc[:,-1]\n",
    "Y_LM_train= Y_LM_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance',n_jobs=-1)\n",
    "\n",
    "sfs2 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs2 = sfs2.fit(X_LM_train, Y_LM_train)\n",
    "feat_cols_2 = list(sfs2.k_feature_idx_)\n",
    "\n",
    "# rfc2 = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=4)\n",
    "rfc2 = LogisticRegression(C=5, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc2.fit(X_LM_train[:, feat_cols_2], Y_LM_train)\n",
    "\n",
    "print(rfc2.score(X_LM_train[:, feat_cols_2],Y_LM_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:  2.4min finished\n",
      "\n",
      "[2019-09-02 02:45:11] Features: 1/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2019-09-02 02:47:34] Features: 2/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2019-09-02 02:49:29] Features: 3/3 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "LP = pd.concat([lepidic,papillary])\n",
    "LP = LP.sample(frac=1)\n",
    "X_LP_train = LP.iloc[:,:-1]\n",
    "X_LP_train = X_LP_train.values\n",
    "Y_LP_train = LP.iloc[:,-1]\n",
    "Y_LP_train = Y_LP_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance',n_jobs=-1)\n",
    "\n",
    "sfs3 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs3 = sfs3.fit(X_LP_train, Y_LP_train)\n",
    "feat_cols_3 = list(sfs3.k_feature_idx_)\n",
    "\n",
    "rfc3 = RandomForestClassifier(n_estimators=20, random_state=42, max_depth=5)\n",
    "# rfc3 = LogisticRegression(C=100, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc3.fit(X_LP_train[:, feat_cols_3], Y_LP_train)\n",
    "\n",
    "print(rfc3.score(X_LP_train[:, feat_cols_3],Y_LP_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:  1.8min finished\n",
      "\n",
      "[2019-09-02 02:51:15] Features: 1/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:52:59] Features: 2/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2019-09-02 02:54:44] Features: 3/3 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "LS = pd.concat([lepidic,solid])\n",
    "LS = LS.sample(frac=1)\n",
    "X_LS_train = LS.iloc[:,:-1]\n",
    "X_LS_train = X_LS_train.values\n",
    "Y_LS_train = LS.iloc[:,-1]\n",
    "Y_LS_train = Y_LS_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance',n_jobs=-1)\n",
    "\n",
    "sfs4 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=9)\n",
    "\n",
    "sfs4 = sfs4.fit(X_LS_train, Y_LS_train)\n",
    "feat_cols_4 = list(sfs4.k_feature_idx_)\n",
    "\n",
    "# rfc4 = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=4)\n",
    "rfc4 = LogisticRegression(C=1, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc4.fit(X_LS_train[:, feat_cols_4], Y_LS_train)\n",
    "\n",
    "print(rfc4.score(X_LS_train[:, feat_cols_4],Y_LS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:    8.9s finished\n",
      "\n",
      "[2019-09-02 02:54:53] Features: 1/3 -- score: 0.876868686868687[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:01] Features: 2/3 -- score: 0.876868686868687[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:09] Features: 3/3 -- score: 0.8677777777777779"
     ]
    }
   ],
   "source": [
    "AM = pd.concat([micro_papillary,acinar])\n",
    "AM = AM.sample(frac=1)\n",
    "X_AM_train = AM.iloc[:,:-1]\n",
    "X_AM_train = X_AM_train.values\n",
    "Y_AM_train = AM.iloc[:,-1]\n",
    "Y_AM_train = Y_AM_train.values\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance',n_jobs=-1)\n",
    "knn = LinearSVC(C=0.00001 , class_weight='balanced',max_iter=10000)\n",
    "\n",
    "sfs5 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs5 = sfs5.fit(X_AM_train, Y_AM_train)\n",
    "feat_cols_5 = list(sfs5.k_feature_idx_)\n",
    "\n",
    "rfc5 = RandomForestClassifier(n_estimators=30, random_state=42, max_depth=10)\n",
    "# rfc5 = LogisticRegression(C=50, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc5.fit(X_AM_train[:, feat_cols_5], Y_AM_train)\n",
    "\n",
    "print(rfc5.score(X_AM_train[:, feat_cols_5],Y_AM_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:    7.8s finished\n",
      "\n",
      "[2019-09-02 02:55:17] Features: 1/5 -- score: 0.6609090909090909[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:    7.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:25] Features: 2/5 -- score: 0.6740909090909091[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:34] Features: 3/5 -- score: 0.7746969696969697[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 827 out of 827 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:43] Features: 4/5 -- score: 0.8095454545454546[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 826 out of 826 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:55:51] Features: 5/5 -- score: 0.8277272727272728"
     ]
    }
   ],
   "source": [
    "AP = pd.concat([papillary,acinar])\n",
    "AP = AP.sample(frac=1)\n",
    "X_AP_train = AP.iloc[:,:-1]\n",
    "X_AP_train = X_AP_train.values\n",
    "Y_AP_train = AP.iloc[:,-1]\n",
    "Y_AP_train = Y_AP_train.values\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance')\n",
    "knn = LinearSVC(C=0.001 , class_weight='balanced',max_iter=10000)\n",
    "\n",
    "sfs6 = sfs(knn, \n",
    "           k_features=5, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs6 = sfs6.fit(X_AP_train, Y_AP_train)\n",
    "feat_cols_6 = list(sfs6.k_feature_idx_)\n",
    "\n",
    "rfc6 = RandomForestClassifier(n_estimators=30, random_state=42, max_depth=10)\n",
    "# rfc6 = LogisticRegression(C=0.0005, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc6.fit(X_AP_train[:, feat_cols_6], Y_AP_train)\n",
    "\n",
    "print(rfc6.score(X_AP_train[:, feat_cols_6],Y_AP_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:    9.6s finished\n",
      "\n",
      "[2019-09-02 02:56:01] Features: 1/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:56:11] Features: 2/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:56:20] Features: 3/3 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "AS = pd.concat([solid,acinar])\n",
    "AS = AS.sample(frac=1)\n",
    "X_AS_train = AS.iloc[:,:-1]\n",
    "X_AS_train = X_AS_train.values\n",
    "Y_AS_train = AS.iloc[:,-1]\n",
    "Y_AS_train = Y_AS_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance')\n",
    "\n",
    "sfs7 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=9)\n",
    "\n",
    "sfs7 = sfs7.fit(X_AS_train, Y_AS_train)\n",
    "feat_cols_7 = list(sfs7.k_feature_idx_)\n",
    "\n",
    "rfc7 = RandomForestClassifier(n_estimators=10, random_state=42, max_depth=4)\n",
    "# rfc7 = LogisticRegression(C=1000, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc7.fit(X_AS_train[:, feat_cols_7], Y_AS_train)\n",
    "\n",
    "print(rfc7.score(X_AS_train[:, feat_cols_7],Y_AS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:   10.4s finished\n",
      "\n",
      "[2019-09-02 02:56:31] Features: 1/4 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:56:41] Features: 2/4 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:56:52] Features: 3/4 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 827 out of 827 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:57:04] Features: 4/4 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "MP = pd.concat([micro_papillary,papillary])\n",
    "MP = MP.sample(frac=1)\n",
    "X_MP_train = MP.iloc[:,:-1]\n",
    "X_MP_train = X_MP_train.values\n",
    "Y_MP_train = MP.iloc[:,-1]\n",
    "Y_MP_train = Y_MP_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance')\n",
    "\n",
    "sfs8 = sfs(knn, \n",
    "           k_features=4, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=10)\n",
    "\n",
    "sfs8 = sfs8.fit(X_MP_train, Y_MP_train)\n",
    "feat_cols_8 = list(sfs8.k_feature_idx_)\n",
    "\n",
    "rfc8 = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)\n",
    "# rfc8 = LogisticRegression(C=100, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc8.fit(X_MP_train[:, feat_cols_8], Y_MP_train)\n",
    "\n",
    "print(rfc8.score(X_MP_train[:, feat_cols_8],Y_MP_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:    7.9s finished\n",
      "\n",
      "[2019-09-02 02:57:12] Features: 1/5 -- score: 0.6262626262626264[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:57:20] Features: 2/5 -- score: 0.8080808080808081[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:57:27] Features: 3/5 -- score: 0.8653198653198653[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 827 out of 827 | elapsed:    6.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:57:33] Features: 4/5 -- score: 0.9203142536475871[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 826 out of 826 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 02:57:41] Features: 5/5 -- score: 0.9326599326599327"
     ]
    }
   ],
   "source": [
    "MS = pd.concat([micro_papillary,solid])\n",
    "MS = MS.sample(frac=1)\n",
    "X_MS_train = MS.iloc[:,:-1]\n",
    "X_MS_train = X_MS_train.values\n",
    "Y_MS_train = MS.iloc[:,-1]\n",
    "Y_MS_train = Y_MS_train.values\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors = 5, weights = 'uniform',n_jobs=-1)\n",
    "knn = LinearSVC(C=0.00001 , class_weight='balanced',max_iter=10000)\n",
    "\n",
    "sfs9 = sfs(knn, \n",
    "           k_features=5, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=9)\n",
    "\n",
    "sfs9 = sfs9.fit(X_MS_train, Y_MS_train)\n",
    "feat_cols_9 = list(sfs9.k_feature_idx_)\n",
    "\n",
    "rfc9 = RandomForestClassifier(n_estimators=40, random_state=42, max_depth=5)\n",
    "# rfc9 = LogisticRegression(C=100, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc9.fit(X_MS_train[:, feat_cols_9], Y_MS_train)\n",
    "\n",
    "print(rfc9.score(X_MS_train[:, feat_cols_9],Y_MS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 830 out of 830 | elapsed:  1.7min finished\n",
      "\n",
      "[2019-09-02 02:59:23] Features: 1/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 829 out of 829 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2019-09-02 03:01:03] Features: 2/3 -- score: 1.0[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 828 out of 828 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "\n",
      "[2019-09-02 03:02:44] Features: 3/3 -- score: 1.0"
     ]
    }
   ],
   "source": [
    "PS = pd.concat([papillary,solid])\n",
    "PS = PS.sample(frac=1)\n",
    "X_PS_train = PS.iloc[:,:-1]\n",
    "X_PS_train = X_PS_train.values\n",
    "Y_PS_train = PS.iloc[:,-1]\n",
    "Y_PS_train = Y_PS_train.values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance',n_jobs=-1)\n",
    "\n",
    "sfs10 = sfs(knn, \n",
    "           k_features=3, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=9)\n",
    "\n",
    "sfs10 = sfs10.fit(X_PS_train, Y_PS_train)\n",
    "feat_cols_10 = list(sfs10.k_feature_idx_)\n",
    "\n",
    "rfc10 = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)\n",
    "# rfc10 = LogisticRegression(C=0.01, penalty='l2',max_iter=5000,solver='liblinear',class_weight='balanced')\n",
    "rfc10.fit(X_PS_train[:, feat_cols_10], Y_PS_train)\n",
    "\n",
    "print(rfc10.score(X_PS_train[:, feat_cols_10],Y_PS_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each classifier is going to give a predicted output, we need to define voting strategies to know what is the actual output using the score matrix given by the confidence score each classifier has in its prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_strategy(M):\n",
    "    max=0\n",
    "    pred=1\n",
    "    for i in range(len(M)):\n",
    "        a=0\n",
    "        for j in range(len(M)):\n",
    "            if j!=i:\n",
    "                if M[i][j] > M[j][i]:\n",
    "                    s=1\n",
    "                else:\n",
    "                    s=0\n",
    "                a=a+s\n",
    "        if a>max:\n",
    "            max=a\n",
    "            pred=i\n",
    "    return pred+1\n",
    "\n",
    "#Taking into account the weight of the prediction score\n",
    "def weighted_voting_strategy(M):\n",
    "    max=0\n",
    "    pred=1\n",
    "    for i in range(len(M)):\n",
    "        a=0\n",
    "        for j in range(len(M)):\n",
    "            if j!=i:\n",
    "                a=a+M[i][j]\n",
    "        if a>max:\n",
    "            max=a\n",
    "            pred=i\n",
    "    return pred+1\n",
    "#Voting strategy eliminating successively the least likely predicted ouputs\n",
    "def output_strategy(M):\n",
    "    for i in range(len(M)-2):\n",
    "        a = np.sum(M, axis = 0)\n",
    "        minimoume=np.inf\n",
    "        for element in a:\n",
    "            if element >0 and element < minimoume:\n",
    "                minimoume = element\n",
    "        b = np.where(a == minimoume)\n",
    "        index = b[0][0]\n",
    "        M[:,index] = 0\n",
    "        M[index,:] = 0\n",
    "    prediction = np.where(M.T == np.max(M))\n",
    "    return prediction[0][0] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 1 4 3 3 3 1 1 3 3 3 4 1 1 1 3 1 4 3 1 1 1 3 1 4 1]\n",
      "[2 4 3 1 5 3 3 3 1 1 3 2 3 5 1 1 1 3 1 4 5 3 2 1 3 1 4 1]\n",
      "[ 1 -1  0  0 -1  0  0  0  0  0  0  1  0 -1  0  0  0  0  0  0 -2 -2 -1  0\n",
      "  0  0  0  0]\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "y_pred=[]\n",
    "for index_element, element in enumerate(X_test):\n",
    "    element_1 = element[feat_cols_1]\n",
    "    element_2 = element[feat_cols_2]\n",
    "    element_3 = element[feat_cols_3]\n",
    "    element_4 = element[feat_cols_4]\n",
    "    element_5 = element[feat_cols_5]\n",
    "    element_6 = element[feat_cols_6]\n",
    "    element_7 = element[feat_cols_7]\n",
    "    element_8 = element[feat_cols_8]\n",
    "    element_9 = element[feat_cols_9]\n",
    "    element_10 = element[feat_cols_10]\n",
    "    \n",
    "    element_1= element_1.reshape(1, -1)\n",
    "    element_2= element_2.reshape(1, -1)\n",
    "    element_3= element_3.reshape(1, -1)\n",
    "    element_4= element_4.reshape(1, -1)\n",
    "    element_5= element_5.reshape(1, -1)\n",
    "    element_6= element_6.reshape(1, -1)\n",
    "    element_7= element_7.reshape(1, -1)\n",
    "    element_8= element_8.reshape(1, -1)\n",
    "    element_9= element_9.reshape(1, -1)\n",
    "    element_10= element_10.reshape(1, -1)\n",
    "    \n",
    "    score_matrix = np.zeros((5,5))\n",
    "    score_matrix[0][2] = rfc1.predict_proba(element_1)[0][0]\n",
    "    score_matrix[0][3] = rfc2.predict_proba(element_2)[0][0]\n",
    "    score_matrix[0][1] = rfc3.predict_proba(element_3)[0][0]\n",
    "    score_matrix[0][4] = rfc4.predict_proba(element_4)[0][0]\n",
    "    score_matrix[2][3] = rfc5.predict_proba(element_5)[0][0]\n",
    "    score_matrix[1][2] = rfc6.predict_proba(element_6)[0][0]\n",
    "    score_matrix[2][4] = rfc7.predict_proba(element_7)[0][0]\n",
    "    score_matrix[1][3] = rfc8.predict_proba(element_8)[0][0]\n",
    "    score_matrix[3][4] = rfc9.predict_proba(element_9)[0][0]\n",
    "    score_matrix[1][4] = rfc10.predict_proba(element_10)[0][0]\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        for j in range(i):\n",
    "            score_matrix[i][j] = 1-score_matrix[j][i]\n",
    "#     y_pred.append(voting_strategy(score_matrix))\n",
    "    y_pred.append(weighted_voting_strategy(score_matrix))\n",
    "#     y_pred.append(output_strategy(score_matrix.T))\n",
    "    \n",
    "    \n",
    "print(np.array(y_pred))\n",
    "print(Y_test)\n",
    "print(np.array(y_pred-Y_test))\n",
    "\n",
    "print(accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "#     classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "#            xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2082deef048>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(Y_test, y_pred,title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
